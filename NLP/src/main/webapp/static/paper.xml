<?xml version="1.0" encoding="UTF-8"?>
<article>
	<title_auther>
	基于改进的 TextRank 算法的中文文本摘要实现 徐馨韬，柴小丽，谢彬，沈晨，王敬平 （中国电子科技集团公司第三十二研究所,上海 201800）	
	</title_auther>
	<context>
		<p type ="txt">
			摘 要：自动摘要抽取在自然语言处理领域有着极其重要的意义，本文针对中文文本的特性提出了融合 Doc2Vec、K-means 聚类和 TextRank 算法的 DK-TextRank 算法，同时针对 K-means 聚类和 TextRank 算法中存在的不足进行了改进。该算法在 使用 Doc2Vec 模型进行句子向量化后，采用改进的 K-means 算法进行聚类，并在每一类簇中分别使用加入特征因子的 TextRank 算法进行排序，最终生成摘要。实验表明，本文提出的 DK-TextRank 算法可以有效生成摘要，效果优于传统的 TF-IDF 和 TextRank 算法，且在摘要数目为 7 时效果最佳，此时的 F 值达到了 79.36%。 关键词：Doc2Vec 模型；K-means 聚类；TextRank 算法；自动摘要；权重影响因子 
		</p>
		<p type ="txt">
			【Abstract】Automatic abstract extraction has extremely important significance in the field of natural language processing. This article proposes p DK-TextRank algorithm that combines Doc2Vec, K-means clustering, and TextRank algorithm for the characteristics of Chinese texts. The DK-TextRank algorithm improves the shortcomings of K-means clustering and TextRank algorithm. After using the Doc2Vec model for sentence vectorization, the DK-TextRank algorithm uses an improved K-means algorithm for clustering, and the TextRank algorithm with feature factors in each cluster to sort. Finally it generates p summary. Experiments show that the DK-TextRank algorithm proposed in this paper can effectively generate p summary, which is better than the traditional TF-IDF and TextRank algorithms. The best results occur when the number of abstracts is 7, and the F value at this time has reached 79.36% . 【Key words】Doc2Vec model；K-means clustering；TextRank algorithm；Automatic summary；Weight influence factor 
		</p>
		<p type ="txt">
			1 概述 随着互联网技术的发展，网络与生活的关系愈 发密切，涵盖的信息也日渐全面。但是，互联网上 海量的信息在给人们生活带来各种便利的同时也导 致了“信息爆炸”的问题。由于周围信息量过于庞 大，人们很难快速、准确地获取自己想要的信息。 因此，如何快速提炼关键信息、获取信息主旨已经 成为一个急需我们解决的问题。 自动摘要系统作为自然语言处理领域一项具有 重大意义的工作，在长文本中提取摘要句，使人们 在短时间内快速了解文章内容，可以极大地提升人 们阅读和获取信息的效率，是应对上述问题的重要 途径之一，引起了国内外的广泛关注。 目前，国外针对自动摘要系统的研究已经有了 初步的成果，针对英文的文本摘要算法被相继提出。 而国内文本摘要抽取尚处于早期研究阶段，针对中 文的文本摘要提取还不够准确，故针对中文特点设 计合适的自动摘要系统仍具有重要意义。 
		</p>
		<p type ="txt">2 相关研究 目前国内外的学者在摘要句抽取方面做了一些研究。</p>
		<p type ="ref" id = "ref1">文献[1]利用文章作者写作时表述观点的语气 和态度、句子主题的依赖性和句子中运用的修辞手 法等综合因素进行摘要句的抽取。</p>
		<p type ="ref" id = "ref2">文献[2]运用不同的权值度量方式，利用同义概念及上下文概念综合 评估句子，以此抽取最能反映文章主题的句子。</p>
		<p type ="ref" id = "ref3">文献[3]将摘要句抽取问题转化为无向图中节点权重计 算问题，利用图中边的权重来衡量其在文章中的重 要程度，以此抽取最终的摘要句。</p>
		<p type ="ref" id = "ref4">文献[4]根据词在 特定文档中出现的频率及在相关文档中出现的范围 来区分文档内容属性.</p>
		<p type ="ref" id = "ref5">文献[5]采用了基于文章语义 信息的摘要方法，通过对文章段落之间的语义关系 进行分析，建立语义网，在对文章进行语义理解的 基础上对摘要句进行抽取。</p>
		<p type ="ref" id = "ref6">文献[6]采用了基于向量 空间模型的方法对文章进行摘要。其利用统计学原 理得到文章的粗摘要句集，并引入空间向量模型， 将粗摘要句表示为向量的方式，使用余弦相似度公 式计算句子间的相似度，删除集合中相似度较高的 冗余句子以提高生成摘要的质量。</p>
		<p type ="ref" id = "ref7">随着神经网络等 人工智能技术的逐渐成熟，文献[7]提出了可以对文 本进行向量化的 Doc2Vec 方法，该方法可以更为全 面的考察语义和上下文等信息。</p>
		<p type ="ref" id = "ref8">经过大量实验，文 献[8-11]提出使用 Doc2Vec 方法在文本聚类领域能 够取得良好的效果。 在聚类算法中，K-means 算法由于聚类效果佳， 故在文本句子聚类中被广泛使用。该算法从向量化 后的数据对象中随机抽取 K 个对象作为初始聚类中 心，而随机抽取初始聚类中心可能会产生聚类效果 不稳定的问题。</p>
		<p type ="ref" id = "ref12">为了解决这一问题，文献[12]提出了 应用二分 K-means 聚类算法对测试用例集的约简方 法，</p>
		<p type ="ref" id = "ref13">文献[13]则采用了密度最大距离最远原则为聚类 算法选取初始聚类中心，</p>
		<p type ="ref" id = "ref14">文献[14]提出了利用过滤后 的频繁项集作为初始聚类中心的方法。</p>
		<p type ="txt">在实际应用 过程中，理想的初始聚类中心相互距离应相对较远， 且各自都能够具有一定代表性。 在摘要句提取方面，TextRank 是最为经典的算 法。TextRank 算法用文本之间的关联性构建有向图， 通过计算每个图节点的权重来挑选摘要句。但是， 传统 TextRank 算法将每个节点的初始权重均设置为 1，忽略了每个节点本身的重要程度。 </p>
		<p type ="ref" id = "ref15">文献[15]提出 每个图节点本身的重要性差异会影响相邻节点的重 要性，进而影响最终的结果。</p>
		<p type ="ref" id = "ref16">文献[16]在传统的 TextRank 算法中加入位置权重，提升了最终的准确度。</p>		
		<p type ="txt">
			3结合Doc2Vec、K-Means聚类与改进的TextRank的自动摘要为提高摘要句提取的准确度，本文选用了能更好结合上下文的Doc2Vec方法对文本中的句子进行向量表达。在此基础上，本文采用了K-Means聚类算法，同时，选用最大距离法作为初始聚类中心，保证聚类的准确性。最后，在每个类簇中使用加权的TextRank算法对每个节点的重要度进行排序，挑选每个类簇中权值最高的句子作为摘要句。本文中文自动摘要流程图如图1所示
		</p>
		<p type ="txt">
			3.1使用Doc2Vec方法的句子向量化Doc2Vec向量训练模型，由Mikolov等人提出，是可以将文档表征为实数向量的方法。该模型使用深度学习的思想，利用多层神经网络，以极大似然作为目标函数建立模型，将每个句子映射成实数向量。经过大量训练后，Doc2Vec模型可以将文本内容的处理抽象为在K维向量空间中的向量运算，且文本语义上的相似度可以用向量空间中的相似度来表示。Doc2Vec工具主要采用了CBOW模型[17]计算机工程（ContinuousBag-Of-Words）和Skip-gram模型[17]。其中，CBOW模型的核心思想是使用上下文对当前汇出现的概率进行预测，而Skip-gram模型则是为了解决训练预料选择的问题。考虑到具体实现，本文选择了CBOW模型进行文本的向量化。
		</p>
		<p type ="txt">
			3.2改进的K-Means聚类K-Means文本聚类的基本算法如下：随机选择K个点作为初始聚类中心，将剩余的每个点按照距离分配给上述K个点，形成K个类簇；然后计算每个类簇的质心，并将其作为下一次迭代的聚类中心，直到测度函数收敛或达到最大迭代次数。其中，两点之间的距离计算方式有欧氏距离、曼哈顿距离、切比雪夫距离、余弦距离、Jaccard相似系数、相关系数等，本文采用欧式距离作为两点之间距离的表达方式，如公式1所示.传统的K-Means聚类算法具有实现简单、时间复杂度低、可解释性强的优点，因此被广泛使用。但是，K-Means聚类的效果和初始聚类中心的选取有密切关联，而采用随机选择数据样本可能会使得算法陷入局部最优而非全局最优，因此，本文在选取初始聚类中心时稍作改进，使得实验中的初始聚类中心相对散开。初始聚类中心的选取方法如下：取所有点的质心作为第一个点；然后对数据集中的每个点，计算该点到已有聚类中心的距离，并基于该距离采用现行概率选择出下一个聚类中心。使用上述方法选取初始聚类中心，可以保证选取的初始聚类中心不至于过于集中，从而避免K-Means聚类算法陷入局部最优的困境，同时也可以满足初始聚类中心选取是随机的。
		</p>
		<p type ="txt">
			3.3改进的TextRank算法传统的TextRank是根据Google的PageRank算法改造得来的，PageRank是一种链接分析算法，用于进行网页排序，是衡量网页重要程度的重要算法。PageRank排序基于其他网页到该网页的链接数量，链接数量越多，该网页越重要。使用TextRank算法时，需要对图中的每个节点指定任意初始值，并进行迭代训练直至收敛，方可计算出各节点的最终权重。传统的TextRank通常将各节点的初值指定为1，忽略了中文写作习惯的影响，如起始句、点题句等句子的重要性比其他句子高。针对这个问题，本文对传统的TextRank算法进行改进，充分考虑到句子位置、点题句等情况对节点权重的影响。
		</p>
		<p type ="txt">
			3.3.1位置关系句子的位置影响句子的重要性，例如出现在段首、段中和段末的句子，重要性是不同的。根据研究表明：在人工摘要中，选取段首句作为摘要的比例高达85%，而选取段尾句作为摘要的比例也接近7%。新闻类的文章首段有很大可能会交代文章主旨，故应适当提高距离开始位置较近的段落及句子的权重。本文采用逐渐降低首段中句子权重，逐渐提高末段中句子权重的方法调整句子权重。本文选取首段前三个句子，和末段全部句子，对相应句子初始权重的调整通过一个权重系数e来实现，权重系数e计算公式如公式5所示
			3.3.2与文章标题相似度在新闻报道中，标题在一定程度上反映文章的主旨信息，因此在正文中和标题形成呼应的句子更有希望成为最终的摘要句。因此本文用余弦相似度来衡量文中句子与标题的相似性，若句子与标题具有较高的相似性，则对该句子的最终权重进行调整。本文的调整规则如公式6所示本文通过带有位置关系信息的公式5调整句子初始权重，将初始权重乘以权重系数e得到TextRank各个节点的初始权重为：eS(V)i，后利用TextRank模型中公式3的方法逐步更新权重，对得到的权重利用公式6加入相似度信息得到最终的句子权重，从而进行排序以提取摘要句。
		</p>
		<p type ="txt">
			4实验过程1、数据收集本文爬取搜狗新闻、新华网、凤凰网等新闻报道，涉及经济、政治、社会、文化、教育等五个方面，共50000篇，为使本文算法针对多类新闻具有普适性，故要求各个方向的新闻数目基本相当。随机从各方向抽取报道1000篇，删除篇幅过少（少于30句）等不利实验分析的文档，剩约4000篇文档，这部分文档作为测试文档，剩余文档作为训练文档用于训练Doc2Vec文本表示模型。抽取测试文档摘要用于验证本文摘要提取算法的效果。
		</p>
		<p type ="txt">
			2、数据预处理1）去除实验噪声。去除对提取摘要无明显影响的图片、表格、特殊符号等计算机语言不易识别的形式。2）文档分割。首先，分割文档为句子从而形成句子集合，继而对这些句子分词、去除停用词，以得到由词项构成的句子集合。需要注意的是，在Doc2Vec深度学习模型的训练学习时，应保证进行分句操作后的句子语序按照原文顺序排布，这样能更好的获取文本上下文语义及相应的语法信息。
		</p>
		<p type ="txt">
			3、向量化句子首先将46000篇报道输入，用于训练Doc2Vec模型。本文选取更加节省存储空间的DBOW模型，实验语言为Python3.5，环境为Anaconda数据处理环境,同时配置了GPU以加速训练过程。向量维度人工确定为200维。将保留原文顺序的全部训练文档串联输入模型进行DBOW模型训练。DBOW模型训练完成后，将进行预处理过的4000篇文章输入模型中，得到可以表征语句中语境、语法及上下文逻辑等信息的200维句子向量集合T，计算机工程则报道可以表示为向量化后的语句所组成的矩阵。
		</p>
		<p type ="txt" >
			4、筛选过滤句子过长或过短的句子都不应该作为摘要候选句。故本文将长度系数C0.8L以及C0.2L的句子去掉。句子长度系数定义如公式7所示：LMLCL公式7其中：L为句子的长度，LM为最长句子的长度。
		</p>
		<p type ="txt">
			5、K-means聚类利用上文提到的改进的K-means算法进行报道中句子向量的聚类。将K值设定为要提取的摘要句数目，最终将新闻报道中的句子划分成K个类簇。
		</p>

		<p type ="txt">
			6、在每个类簇中进行改进的TextRank权值计算传统的K-Means算法选取最终摘要句时，通常选择距离聚类中心最近的句子。但是，该方法并不能保证提取的摘要句是在该类簇中所有句子的最佳代表。故本文在挑选摘要句时，利用改进的TextRank算法，对每个类簇中的句子进行权重排序，进而挑选出最能代表每个类簇的句子作为摘要句。
		</p>

		<p type ="txt">
			7、摘要输出利用改进后的TextRank排序后的句子按原文中的顺序输出，保证提取出的摘要的连贯性。
		</p>

		<p type ="txt">
			5摘要效果评测及结果分析对自动摘要效果的评价通常采用内部评价方法，即通过与人工撰写的摘要相比较来评价文摘的质量。机器学习中的准确率(Precision)和召回率(Recall)经常被用来作为评价自动摘要结果质量的指标，摘要准确率用来评价摘要表现原文主体信息的准确度，而摘要召回率则用来评价摘要句对原文主题信息的覆盖程度，F值则是摘要准确率和摘要召回率的调和平均值。本文实验采用F值来衡量聚类效果，它综合平衡准确率和召回率，一般F值越高，说明聚类的效果越好，计算公式如公式8、9、10：本文中改进的DK-TextRank算法效果优于TF-IDF及传统的TextRank算法。因为首先利用K-Means算法将文本划分为若干具有相计算机工程关关系的类簇，再用TextRank算法选取了每个具有相关关系的类簇中最能代表整个类簇的点，同时，还考虑到了中文文本中语句位置和标题相似度对句子重要度的影响。故和传统的TextRank算法相比，本文提出的算法在选取摘要句方面更具代表性，故取得了更好的实验结果。与此同时，从图4中可以发现，随着抽取摘要句数目的增加，F值呈现先上升后下降的趋势，当摘要句数目为7时F值最大，此时采用本文提出的DK-TextRank算法的F值达到79.36%。经进一步分析，在摘要数目为7时效果最佳的原因是采用人工标注的摘要句数目通常为7句左右。
		</p>
		<p type ="txt">
			6结束语自动摘要技术能够帮助人们解决“信息爆炸”时代带来的难以获取有效信息的问题,目前是一个热门的研究方向。本文将Doc2Vec、K-means聚类和TextRank算法相结合，在使用Doc2Vec模型生成句子向量集的基础上，运用改进的K-means聚类算法进行聚类，最后在每个类簇中利用加入位置关系及与标题相似性等特征的TextRank算法进行重要度排序，提取最终摘要句。本文用各类新闻报道进行抽取摘要句的实验，实验结果表明，相对于传统的TF-IDF和TextRank算法而言，本文提出的DK-TextRank算法能够有效提高摘要句的质量。
		</p>
	</context>
	<reference>
		<r id ="ref1">L 原田，宗樹，柳本等．Topic Sentence Extraction from Editorial Articles Based on Sentence Structure and Topic Relevance[J]. システム制御情報学会研究発表講演会 講演論文集，2013, 57.</r>
		<r id ="ref2">张云涛，龚玲，王永成．基于综合方法的文本主题句的 自动抽取[J]．上海交通大学学报， 2006, 40(5): 771-774．</r>
		<r id ="ref3">Yeh J. Ke H. Yang W. iSpreadRank: Ranking sentences for extraction-based summarization using feature weight propagation in the sentence similarity networkp[J]. Expert Systems with Applications. 2008. 35(3): 1451-1462. </r>
		<r id ="ref4">Salton G, Yu C T. On the construction of effective vocabularies for information retrieval[C]// Meeting on Programming Languages and Information Retrieval. ACM, 1973:48-60.</r>
		<r id ="ref5">张奇，黄萱菁，吴立德．一种新的句子相似度度量及其 在文本自动摘要中的应用 [J] ．中文信息学报， 2005,19(2):93-99</r>
		<r id ="ref6">张筱丹，胡学钢．基于向量空间模型的自动摘要冗余处 理研究 [J] ．合肥工业大学学报自然科学版， 2010,33(9):1355-1358</r>
		<r id ="ref7">Le Q, Mikolov T. Distributed Representations of Sentences and Documents[C]//Proceedings of International Conference on Machine Learning. 2014.</r>
		<r id ="ref8">甘如饴. 基于 doc2vec 和 SVM 的舆情情感分析系统的 研究与设计[D].北京邮电大学,2017. </r>
		<r id ="ref9"> Dai X, Bikdash M, Meyer B. From Social Media to Public Health Surveillance:Word Embedding Based Clustering Method for Twitter Classification [C]// Proceedings of Southeast Con. IEEE,2017.</r>
		<r id ="ref10">Wenbing Chang,Zhenzhong Xu,Shenghan Zhou,Wen Cao. Research on detection methods based on Doc2vec abnormal comments[J]. Future Generation Computer Systems,2018,86. </r>
		<r id ="ref11">李依尘. 面向自动问答的中学历史知识库构建[D].哈尔 滨工业大学,2017. </r>
		<r id ="ref12">汪文靖,冯瑞. 基于二分 K-means 的测试用例集约简方 法[J]. 计算机工程, 2016, 42(12): 73-77,83. </r>
		<r id ="ref13">贾晓婷,王名扬,曹宇. 结合 Doc2Vec 与改进聚类算法的 中文单文档自动摘要方法研究[J]. 数据分析与知识发 现，2018,14(2):86-95.</r>
		<r id ="ref14">张银明,黄廷磊,林科,等. 一种改进的 k 均值文本聚类 算法[J]. 桂林电子科技大学学报, 2016, 36(4): 311-314</r>
		<r id ="ref15">夏天. 词语位置加权 TexTRank 的关键词抽取研究［J］. 现代图书情报技术,2013(9):30-34.</r>
		<r id ="ref16">罗庆平. 基于信息融合的 Web 信息可信度研究[D]. 长 沙: 中南大学,2014. </r>
		<r id ="ref17">Tomas M, Kai C, Greg C, et al. Efficient Estimation of Word Representations in Vector Space [OL]. ArXiv, 2013. ArXiv: 1301.3781v3.</r>
	</reference>
</article>